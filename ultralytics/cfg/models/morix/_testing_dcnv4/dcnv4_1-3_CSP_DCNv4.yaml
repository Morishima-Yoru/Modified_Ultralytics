
nc: 1000 
scales:
  n: [0.33, 0.5, 1024]

# DCNv4 requires Layer Normalization. 
# Train doesn't converge when using Batch Normalization to DCNv4.

# In this class (CSP_DCNv4), the Normalization parameter will only affect stray norm layer (CSP Transition)

backbone:
  # [from, repeats, module, args]
  - [-1, 1, CNA, [64,   3, 2, None, 1, 1, nn.GELU, nn.BatchNorm2d]] # 0-P1/2
  - [-1, 1, CNA, [128,  3, 2, None, 1, 1, nn.GELU, nn.BatchNorm2d]] # 1-P2/4
  - [-1, 3, CSP_DCNv4, [128 , None, True, True, nn.GELU, nn.BatchNorm2d]]
  - [-1, 1, CNA, [256,  3, 2, None, 1, 1, nn.GELU, nn.BatchNorm2d]] # 3-P3/8
  - [-1, 6, CSP_DCNv4, [256 , None, True, True, nn.GELU, nn.BatchNorm2d]]
  - [-1, 1, CNA, [512,  3, 2, None, 1, 1, nn.GELU, nn.BatchNorm2d]] # 5-P4/16
  - [-1, 6, CSP_DCNv4, [512 , None, True, True, nn.GELU, nn.BatchNorm2d]]
  - [-1, 1, CNA, [1024, 3, 2, None, 1, 1, nn.GELU, nn.BatchNorm2d]] # 7-P5/32
  - [-1, 3, CSP_DCNv4, [1024, None, True, True, nn.GELU, nn.BatchNorm2d]]
  
head:
  - [-1, 1, ClassificationHead, [nc]] 
